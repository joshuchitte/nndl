{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sharvaree Bamane/2015011"
      ],
      "metadata": {
        "id": "gRcxiwIBfqnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlUcth7EbNQh",
        "outputId": "145b0036-c500-4949-bc15-13c41e96421f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "syns=wordnet.synsets('sad')\n",
        "print(syns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clU5zKWubpeT",
        "outputId": "4784c3cf-0b39-4945-97e9-75e8a1b2346b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('sad.a.01'), Synset('sad.s.02'), Synset('deplorable.s.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "synonyms=[]\n",
        "antonyms=[]\n",
        "\n",
        "for syn in wordnet.synsets (\"inside\"):\n",
        "  for l in syn.lemmas():\n",
        "    synonyms.append (l.name())\n",
        "    if l.antonyms():\n",
        "      antonyms.append (l.antonyms()[0].name())\n",
        "      print(set(synonyms))\n",
        "      print(set(antonyms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EIJok6Df05x",
        "outputId": "84fce555-13fc-4bcb-8492-e2f040cbdef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'inside'}\n",
            "{'outside'}\n",
            "{'interior', 'inside'}\n",
            "{'outside'}\n",
            "{'interior', 'inside'}\n",
            "{'outside'}\n",
            "{'privileged', 'inner', 'interior', 'inside'}\n",
            "{'outside'}\n",
            "{'privileged', 'inner', 'inside', 'interior', 'indoors'}\n",
            "{'outdoors', 'outside'}\n",
            "{'privileged', 'inner', 'inside', 'interior', 'indoors'}\n",
            "{'outdoors', 'outside'}\n",
            "{'within', 'inwardly', 'privileged', 'inner', 'inside', 'interior', 'indoors'}\n",
            "{'outdoors', 'outwardly', 'outside'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POST LAB WORK"
      ],
      "metadata": {
        "id": "YJlG_2P3f-Np"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypernyms and Hyponyms"
      ],
      "metadata": {
        "id": "-31tceVPoTH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IemuZO4dgCpw",
        "outputId": "116f2f17-d757-47f1-9b76-bdb43645d525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "syns=wordnet.synsets('Angry')\n",
        "print(syns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sx6RnWwgrvZ",
        "outputId": "8e28b9ca-270e-4e07-bb13-94b2192cf5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('angry.a.01'), Synset('angry.s.02'), Synset('angry.s.03')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "hypernyms=[]\n",
        "hyponyms=[]\n"
      ],
      "metadata": {
        "id": "s35d-tQdgt7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for syn in wordnet.synsets (\"book\"):\n",
        "  for l in syn.lemmas():\n",
        "    hypernyms.append (l.name())\n",
        "    if l.hyponyms():\n",
        "      hyponyms.append (l.hyponyms()[0].name())\n",
        "print(set(hypernyms))\n",
        "print(set(hyponyms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxOhhdXWi7XD",
        "outputId": "f4d73142-6ec6-4fee-b4f2-868999e6f948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rule_book', 'Word', 'leger', 'Koran', 'Holy_Scripture', 'Scripture', 'volume', 'book', 'hold', 'Word_of_God', 'ledger', 'Good_Book', 'Christian_Bible', 'record', \"al-Qur'an\", 'Book', 'reserve', 'record_book', 'book_of_account', 'script', 'playscript', 'account_book', 'Bible', 'Holy_Writ', 'Quran'}\n",
            "set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meronymy and Holonymy"
      ],
      "metadata": {
        "id": "raqJsFLYobBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JScEDkogqFff",
        "outputId": "3035c5c6-ebe8-4fe5-8281-35553d1c6a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "syns=wordnet.synsets('happy')\n",
        "print(syns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX3UdFekqFpL",
        "outputId": "cdc80333-eefb-4a12-968c-b4a29073fb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('happy.a.01'), Synset('felicitous.s.02'), Synset('glad.s.02'), Synset('happy.s.04')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "meronyms=[]\n",
        "holonyms=[]"
      ],
      "metadata": {
        "id": "EQ461w3fqFr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for syn in wordnet.synsets(\"wheel\"):\n",
        "    for lemma in syn.lemmas():\n",
        "        meronyms.append(lemma.name())\n",
        "\n",
        "\n",
        "    if syn.part_holonyms():\n",
        "        for holonym in syn.part_holonyms():\n",
        "            holonyms.append(holonym.name())\n",
        "\n",
        "\n",
        "print(set(meronyms))\n",
        "print(set(holonyms))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQcKVOGgrpMu",
        "outputId": "dbbb6d04-2aae-441f-f8a3-e1387ab15531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cycle', 'steering_wheel', 'wheel_around', 'roulette_wheel', 'bike', 'bicycle', 'roll', 'pedal', 'wheel', 'rack'}\n",
            "{'steering_system.n.01', 'wheeled_vehicle.n.01'}\n"
          ]
        }
      ]
    }
  ]
}